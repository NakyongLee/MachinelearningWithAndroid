#pandasë¡œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd


data = pd.read_csv('chunk0.csv', encoding='utf-8')
category = pd.read_csv('bunjang_category.csv', encoding='utf-8')
#data.head()

#columnì •ë¦¬ í›„ keyword, category_idì—ì„œ nullê°’ ì§€ìš°ê¸°
col = ['name', 'keyword', 'category_id', 'description']
data = data[col]
data = data[pd.notnull(data['keyword'])]
data = data[pd.notnull(data['category_id'])]
#data.to_csv("test.csv", encoding="utf-8")
data.shape

#import re
#re_sc = re.compile('[\!@#$%\^&\*\(\)\-=_\[\]\{\}\.,/\?~\+\'"|]')
#íŠ¹ìˆ˜ë¬¸ì ì œê±°

data['name'] = data['name'].str.replace(pat = r'[â€»â˜…â™¥\!@#âœ”$%\^&\*\(\)\-=_\[\]\{\}\.,/\?~\+\'"|]', repl=r' ', regex=True) #íŠ¹ìˆ˜ë¬¸ìì œê±°
data['name'] = data['name'].str.replace(pat=r'[\s\s+]', repl= r' ', regex=True) #ë¶ˆí•„ìš”í•œ ê³µë°±
data['keyword'] = data['keyword'].str.replace(pat = r'[â˜…â™¥\!@#$%\^&\*\(\)\-=_\[\]\{\}\.,/\?~\+\'"|]', repl=r' ', regex=True)
data['keyword'] = data['keyword'].str.replace(pat=r'[\s\s+]', repl= r' ', regex=True)
data['description'] = data['description'].str.replace(pat = r'[â€»âœ”ğŸ’œâ˜…â™¥\!@#$%\^&\*\(\)\-=_\[\]\{\}\.,/\?~\+\'"|]', repl=r' ', regex=True)
data['description'] = data['description'].str.replace(pat=r'[\s\s+]', repl= r' ', regex=True)
data['description'] = data['description'].str.replace(pat=r'[\n\n+]', repl= r' ', regex=True)

#display(data)

print(data.isnull().sum()) #ë°ì´í„° í”„ë ˆì„ nullê°’ í™•ì¸

#testìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
testpd = pd.DataFrame(data['keyword'], columns=['keyword'])
testpd['category_id'] = data['category_id']
#display(tfidfdata)

#category_id intí˜•ë³€í™˜ ë° ëŒ€ë¶„ë¥˜ ì¶”ì¶œ
import numpy as np
#testpd = testpd[pd.notnull(testpd['category_id'])]
#testpd = testpd[pd.notnull(testpd['keyword'])]
print(testpd.isnull().sum())
def tokenizer_category_id(number):
    while (number > 1000) :
        number = number / 1000
    return int(number)

#int_id = testpd['category_id'].apply(tokenizer_category_id)
testpd['int_id'] = testpd['category_id'].apply(tokenizer_category_id)
testpd['int_id'] = testpd['int_id'].apply(np.int64)

display(testpd)

from sklearn.feature_extraction.text import CountVectorizer #ì¹´ìš´íŠ¸ ë²¡í„°
from sklearn.feature_extraction.text import TfidfTransformer  #TFIDF
from sklearn.model_selection import train_test_split  #ë°ì´í„° ë‚˜ëˆ„ê¸°
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB # ë‹¤í•­ë¶„í¬ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸
from sklearn.metrics import accuracy_score #ì •í™•ë„ ê³„ì‚°


'''name_tokenê³¼ keywordí•¨ê»˜ ì‚¬ìš©í•˜ëŠ” data
testpd2 = pd.DataFrame(data['name_token'], columns=['name_token'])
testpd2['int_id'] = testpd['int_id']
testpd2['name_token2'] = testpd2['name_token'].apply(' '.join)
testpd2['keyword'] = data['keyword']
name_and_keyword = testpd2['name_token2'] + " " + testpd2['keyword']
X_train, X_test, y_train, y_test = train_test_split(name_and_keyword, tttttt['int_id'], random_state = 0)#ë°ì´í„° ë‚˜ëˆ„
'''

#keywordë§Œ ì‚¬ìš©
X_train, X_test, y_train, y_test = train_test_split(tfidfdata['keyword'], tfidfdata['int'], random_state = 0)#ë°ì´í„° ë‚˜ëˆ„ê¸°
count_vect = CountVectorizer() #ì¹´ìš´íŠ¸ ë²¡í„°
tfidf_transformer = TfidfTransformer() #TF-IDF

#training dataì—ì„œëŠ” fit_transformì‚¬ìš©
X_train_counts = count_vect.fit_transform(X_train)
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

#test dataì—ì„œëŠ” transformì‚¬ìš©
X_test_counts = count_vect.transform(X_test)
X_test_tfidf = tfidf_transformer.transform(X_test_counts)

#ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
#ì¹´ìš´íŠ¸ë²¡í„°
model = MultinomialNB()
model.fit(X_train_counts, y_train)

model2 = LinearSVC()
model2.fit(X_train_counts, y_train)

#y_train_pred = model.predict(X_train_counts)
#y_train_pred2 = model2.predict(X_train_counts)
y_test_pred = model.predict(X_test_counts)
y_test_pred2 = model2.predict(X_test_counts)
y_test_pred_2 = model.predict(X_test_tfidf)
y_test_pred2_2 = model2.predict(X_test_tfidf)

#TF-IDF ë²¡í„°
model3 = MultinomialNB()
model3.fit(X_train_tfidf, y_train)

model4 = LinearSVC()
model4.fit(X_train_tfidf, y_train)

#y_train_pred3 = model3.predict(X_train_tfidf)
#y_train_pred4 = model4.predict(X_train_tfidf)
y_test_pred3 = model3.predict(X_test_tfidf)
y_test_pred4 = model4.predict(X_test_tfidf)
y_test_pred3_2 = model.predict(X_test_counts)
y_test_pred4_2 = model2.predict(X_test_counts)

print("count í•™ìŠµ í›„ count + naive : ", accuracy_score(y_test, y_test_pred))
print("count í•™ìŠµ í›„ count + svm : ", accuracy_score(y_test, y_test_pred2))
print("count í•™ìŠµ í›„ tfidf + naive: ", accuracy_score(y_test, y_test_pred_2))
print("count í•™ìŠµ í›„ tfidf + svm : ", accuracy_score(y_test, y_test_pred2_2))
print("TF-IDF í•™ìŠµ í›„ tf-idf + naive : ", accuracy_score(y_test, y_test_pred3))
print("TF-IDF í•™ìŠµ í›„ tf-idf + svm : ", accuracy_score(y_test, y_test_pred4))
print("TF-IDF í•™ìŠµ í›„ count + naive: ", accuracy_score(y_test, y_test_pred3_2))
print("TF-IDF í•™ìŠµ í›„ count + svm : ", accuracy_score(y_test, y_test_pred4_2))